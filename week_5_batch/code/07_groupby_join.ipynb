{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GroupBy video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/04/07 08:36:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "  .master(\"local[*]\") \\\n",
    "  .appName(\"test\") \\\n",
    "  .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_green = spark.read.parquet('../../../data/pg/green/*/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/apache-spark/3.5.0/libexec/python/pyspark/sql/dataframe.py:329: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  warnings.warn(\"Deprecated in 2.0, use createOrReplaceTempView instead.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "df_green.registerTempTable(\"green\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_green_revenue = spark.sql(\"\"\"\n",
    "  SELECT \n",
    "    -- Reveneue grouping \n",
    "    date_trunc('hour', lpep_pickup_datetime) AS hour,\n",
    "    PULocationID AS zone,\n",
    "\n",
    "    SUM(total_amount) AS amount,\n",
    "    COUNT(1) AS number_records\n",
    "  FROM green\n",
    "  WHERE lpep_pickup_datetime >= '2020-01-01 00:00:00'\n",
    "  GROUP BY 1, 2\n",
    "  ORDER BY 1, 2\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/06 10:51:05 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 95,00% for 8 writers\n",
      "24/04/06 10:51:05 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 84,44% for 9 writers\n",
      "24/04/06 10:51:05 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 76,00% for 10 writers\n",
      "24/04/06 10:51:05 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 84,44% for 9 writers\n",
      "24/04/06 10:51:05 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 76,00% for 10 writers\n",
      "24/04/06 10:51:05 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 69,09% for 11 writers\n",
      "24/04/06 10:51:05 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 76,00% for 10 writers\n",
      "24/04/06 10:51:05 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 84,44% for 9 writers\n",
      "24/04/06 10:51:05 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 95,00% for 8 writers\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_green_revenue \\\n",
    "  .repartition(20) \\\n",
    "  .write.parquet(\"../../../data/report/revenue/green\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 26:===================>                                     (4 + 8) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----+------------------+--------------+\n",
      "|               hour|zone|            amount|number_records|\n",
      "+-------------------+----+------------------+--------------+\n",
      "|2020-01-01 00:00:00|   7| 769.7299999999997|            45|\n",
      "|2020-01-01 00:00:00|  17|            195.03|             9|\n",
      "|2020-01-01 00:00:00|  18|               7.8|             1|\n",
      "|2020-01-01 00:00:00|  22|              15.8|             1|\n",
      "|2020-01-01 00:00:00|  24|              87.6|             3|\n",
      "|2020-01-01 00:00:00|  25|             531.0|            26|\n",
      "|2020-01-01 00:00:00|  29|              61.3|             1|\n",
      "|2020-01-01 00:00:00|  32| 68.94999999999999|             2|\n",
      "|2020-01-01 00:00:00|  33|317.27000000000004|            11|\n",
      "|2020-01-01 00:00:00|  35|129.95999999999998|             5|\n",
      "|2020-01-01 00:00:00|  36|295.34000000000003|            11|\n",
      "|2020-01-01 00:00:00|  37|175.67000000000002|             6|\n",
      "|2020-01-01 00:00:00|  38| 98.78999999999999|             2|\n",
      "|2020-01-01 00:00:00|  40|168.98000000000002|             8|\n",
      "|2020-01-01 00:00:00|  41|1363.9599999999987|            84|\n",
      "|2020-01-01 00:00:00|  42| 799.7599999999994|            52|\n",
      "|2020-01-01 00:00:00|  43|            107.52|             6|\n",
      "|2020-01-01 00:00:00|  47|              13.3|             1|\n",
      "|2020-01-01 00:00:00|  49|266.76000000000005|            14|\n",
      "|2020-01-01 00:00:00|  51|              17.8|             2|\n",
      "+-------------------+----+------------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_green_revenue.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yellow = spark.read.parquet('../../../data/pg/yellow/*/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yellow.registerTempTable(\"yellow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yellow_revenue = spark.sql(\"\"\"\n",
    "  SELECT \n",
    "    -- Reveneue grouping \n",
    "    date_trunc('hour', tpep_pickup_datetime) AS hour,\n",
    "    PULocationID AS zone,\n",
    "\n",
    "    SUM(total_amount) AS amount,\n",
    "    COUNT(1) AS number_records\n",
    "  FROM yellow\n",
    "  WHERE tpep_pickup_datetime >= '2020-01-01 00:00:00'\n",
    "  GROUP BY 1, 2\n",
    "  ORDER BY 1, 2\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/06 10:46:41 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 95,00% for 8 writers\n",
      "24/04/06 10:46:41 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 84,44% for 9 writers\n",
      "24/04/06 10:46:41 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 76,00% for 10 writers\n",
      "24/04/06 10:46:41 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 69,09% for 11 writers\n",
      "24/04/06 10:46:41 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 63,33% for 12 writers\n",
      "24/04/06 10:46:41 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 69,09% for 11 writers\n",
      "24/04/06 10:46:41 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 76,00% for 10 writers\n",
      "24/04/06 10:46:41 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 84,44% for 9 writers\n",
      "24/04/06 10:46:41 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 95,00% for 8 writers\n",
      "24/04/06 10:46:42 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 95,00% for 8 writers\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_yellow_revenue \\\n",
    "  .repartition(20) \\\n",
    "  .write.parquet(\"../../../data/report/revenue/yellow\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 73:===================================================>    (12 + 1) / 13]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----+------------------+--------------+\n",
      "|               hour|zone|            amount|number_records|\n",
      "+-------------------+----+------------------+--------------+\n",
      "|2020-01-01 00:00:00|   3|              25.0|             1|\n",
      "|2020-01-01 00:00:00|   4|1004.3000000000002|            57|\n",
      "|2020-01-01 00:00:00|   7| 455.1700000000001|            38|\n",
      "|2020-01-01 00:00:00|  10|             42.41|             2|\n",
      "|2020-01-01 00:00:00|  12|             107.0|             6|\n",
      "|2020-01-01 00:00:00|  13|1214.7999999999997|            56|\n",
      "|2020-01-01 00:00:00|  14|               8.8|             1|\n",
      "|2020-01-01 00:00:00|  15|             34.09|             1|\n",
      "|2020-01-01 00:00:00|  17|220.20999999999998|             8|\n",
      "|2020-01-01 00:00:00|  18|               5.8|             1|\n",
      "|2020-01-01 00:00:00|  24|            754.95|            45|\n",
      "|2020-01-01 00:00:00|  25|            324.35|            16|\n",
      "|2020-01-01 00:00:00|  32|              18.0|             1|\n",
      "|2020-01-01 00:00:00|  33|255.56000000000003|             8|\n",
      "|2020-01-01 00:00:00|  34|              19.3|             1|\n",
      "|2020-01-01 00:00:00|  36|            109.17|             3|\n",
      "|2020-01-01 00:00:00|  37|            161.61|             7|\n",
      "|2020-01-01 00:00:00|  40|             89.97|             5|\n",
      "|2020-01-01 00:00:00|  41|1256.5299999999997|            80|\n",
      "|2020-01-01 00:00:00|  42| 635.3500000000001|            46|\n",
      "+-------------------+----+------------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_yellow_revenue.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_green_revenue_tmp = df_green_revenue \\\n",
    "  .withColumnRenamed('amount', 'green_amount') \\\n",
    "  .withColumnRenamed('number_records', 'green_number_records')\n",
    "  \n",
    "df_yellow_revenue_tmp = df_yellow_revenue \\\n",
    "  .withColumnRenamed('amount', 'yellow_amount') \\\n",
    "  .withColumnRenamed('number_records', 'yellow_number_records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join = df_green_revenue_tmp.join(df_yellow_revenue_tmp, on=['hour', 'zone'], how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/07 08:42:19 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 95,00% for 8 writers\n",
      "24/04/07 08:42:19 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 84,44% for 9 writers\n",
      "24/04/07 08:42:19 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 76,00% for 10 writers\n",
      "24/04/07 08:42:19 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 69,09% for 11 writers\n",
      "24/04/07 08:42:19 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 63,33% for 12 writers\n",
      "24/04/07 08:42:20 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 69,09% for 11 writers\n",
      "24/04/07 08:42:20 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 76,00% for 10 writers\n",
      "24/04/07 08:42:20 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 84,44% for 9 writers\n",
      "24/04/07 08:42:20 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 95,00% for 8 writers\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_join.write.parquet('../../../data/report/total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 13:===================================================>    (12 + 1) / 13]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----+------------------+--------------------+------------------+---------------------+\n",
      "|               hour|zone|      green_amount|green_number_records|     yellow_amount|yellow_number_records|\n",
      "+-------------------+----+------------------+--------------------+------------------+---------------------+\n",
      "|2020-01-01 00:00:00|  55|129.29000000000002|                   4|              NULL|                 NULL|\n",
      "|2020-01-01 00:00:00|  60|            160.04|                   6|57.620000000000005|                    2|\n",
      "|2020-01-01 00:00:00|  61|            526.71|                  17|            146.64|                    3|\n",
      "|2020-01-01 00:00:00|  65|            199.49|                  10|            409.35|                   19|\n",
      "|2020-01-01 00:00:00|  71|              23.8|                   1|              NULL|                 NULL|\n",
      "|2020-01-01 00:00:00|  78|             34.46|                   2|              NULL|                 NULL|\n",
      "|2020-01-01 00:00:00|  88|              NULL|                NULL| 823.8000000000002|                   36|\n",
      "|2020-01-01 00:00:00| 106|             10.56|                   1|              NULL|                 NULL|\n",
      "|2020-01-01 00:00:00| 112|312.26000000000005|                  18|119.47999999999999|                    8|\n",
      "|2020-01-01 00:00:00| 161|              NULL|                NULL| 9410.210000000021|                  488|\n",
      "|2020-01-01 00:00:00| 162|              NULL|                NULL| 4622.289999999997|                  268|\n",
      "|2020-01-01 00:00:00| 185|              NULL|                NULL|             69.51|                    2|\n",
      "|2020-01-01 00:00:00| 190|             61.97|                   4|              54.1|                    3|\n",
      "|2020-01-01 00:00:00| 194|              NULL|                NULL|            148.71|                    2|\n",
      "|2020-01-01 00:00:00| 242|             64.25|                   1|              NULL|                 NULL|\n",
      "|2020-01-01 00:00:00| 255| 666.3399999999999|                  28| 537.6600000000001|                   27|\n",
      "|2020-01-01 00:00:00| 258|              45.3|                   1|              NULL|                 NULL|\n",
      "|2020-01-01 01:00:00|   3|46.230000000000004|                   2|              NULL|                 NULL|\n",
      "|2020-01-01 01:00:00|  40|177.16000000000003|                   6|            313.54|                   15|\n",
      "|2020-01-01 01:00:00|  45|              NULL|                NULL| 898.4399999999999|                   49|\n",
      "+-------------------+----+------------------+--------------------+------------------+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_join.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joining big table & small table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join = spark.read.parqute('../../../data/report/total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read \\\n",
    "  .option(\"header\", \"true\") \\\n",
    "  .csv(\"../../../data/taxi+_zone_lookup.csv\")\n",
    "  \n",
    "df.write.parquet(\"../../../data/zones\", mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones = spark.read.parquet(\"../../../data/zones\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = df_join.join(df_zones, df_join.zone == df_zones.LocationID, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/07 09:03:18 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 95,00% for 8 writers\n",
      "24/04/07 09:03:18 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 84,44% for 9 writers\n",
      "24/04/07 09:03:18 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 95,00% for 8 writers\n",
      "24/04/07 09:03:19 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 95,00% for 8 writers\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_result.drop('LocationsID', 'zone').write.parquet('../../../data/tmp/revenue-zones')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
